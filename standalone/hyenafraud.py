# -*- coding: utf-8 -*-
"""HyenaFraud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xLN7unX7j_RJuX8jWi4dyec88WoC-MD-
"""

import torch
import pandas as pd
import math
import dataclasses
from typing import List, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
# usei esse dataset: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
# da pra puxar por biblioteca mas achei mais facil jogar aqui
# implementei baseado no paper e nesse github aqui: https://github.com/expz/annotated-hyena/blob/master/annotated_hyena.ipynb
# a principal diferenca eh o uso da mlp, ele percebeu que em problemas mais simples, um filtro fixo bate o mlp
#d_model, o tamanho o vetor de cada token
# N, quantos gates o hyena vai ter
# conv_len
class Projection(torch.nn.Module):
  def __init__(self, d_model: int, N: int, conv_len: int):
    super().__init__()
    self.d_model = d_model
    self.N = N
    self.linear = torch.nn.Linear(d_model, d_model * (N + 1))
    self.conv = torch.nn.Conv1d(
      in_channels=d_model * (N + 1),
      out_channels=d_model * (N + 1),
      kernel_size=conv_len,
      groups=d_model * (N + 1),  # Depthwise convolution
      padding=conv_len - 1,
    )

  def forward(self, u: torch.Tensor) -> List[torch.Tensor]:
    z = self.linear(u) #engorda o dado para ser trabalhado (d_model, d_model * N*1)
    z = z.transpose(1, 2)  # Channels (embedding dim) needs to come first

    L = z.shape[2]
    z = self.conv(z)[..., :L]

    x = torch.split(z, self.d_model, dim=1)
    return x

@dataclasses.dataclass
class HyenaConfig:
    d_model: int
    n_layers: int
    d_embed: int
    d_filter_mlp: int
    n_filter_layers: int
    context_length: int
    short_conv_size: int
    order: int
    pdrop_hyena: float
    pdrop_embed: float
    omega: int
    epochs: int
    learning_rate: float
    betas: Tuple[float, float]
    weight_decay: float
    device_type: str
    precision: str
    batch_size: int
    num_workers: int

class FFTConv(torch.nn.Module):
  def __init__(self):
    super().__init__()

  def forward(
      self,
      h: torch.Tensor, #filter
      x: torch.Tensor, #input data
      B: torch.Tensor  #bias
    ) -> torch.Tensor:
    L = h.shape[-1]
    h_f = torch.fft.rfft(h, n=2 * L, norm="forward")
    x_f = torch.fft.rfft(x.to(dtype=h.dtype), n=2 * L)
    y = torch.fft.irfft(h_f * x_f, n=2 * L, norm="forward")[..., :L]
    y = y + x * B
    y = y.to(dtype=h.dtype)  # y is ComplexFloat but we need it to be float
    return y

class HyenaBlock(torch.nn.Module):
    def __init__(self, config: HyenaConfig, use_mlp_filter: bool = True):
        super().__init__()
        self.proj_input = Projection(config.d_model, config.order, config.short_conv_size)
        self.proj_output = torch.nn.Linear(config.d_model, config.d_model)

        if use_mlp_filter:
            print("Iniciando HyenaBlock com Parametrização (MLP) ...")
            self.filter = ImplicitHyenaFilter(
                d_model=config.d_model,
                d_mlp=config.d_filter_mlp,
                N=config.order,
                max_seq_len=config.context_length
            )
        else:
            print("Iniciando HyenaBlock com Filtro Fixo ...")
            self.filter = HyenaFilter(
                d_model=config.d_model,
                d_mlp=config.d_filter_mlp,
                d_embed=config.d_embed,
                N=config.order,
                n_layers=config.n_filter_layers,
                max_seq_len=config.context_length,
                omega=config.omega,
            )

        self.dropout = torch.nn.Dropout(config.pdrop_hyena)
        self.fft_conv = FFTConv()
        self.B = torch.nn.Parameter(torch.randn((config.order, 1, config.d_model, 1)))

    def forward(self, u: torch.Tensor) -> torch.Tensor:
        L = u.shape[1]

        *x, v = self.proj_input(u)
        v = v + u.transpose(1, 2)  # skip connection

        h = self.filter(L)

        for i, x_i in enumerate(x):
          h_i = h[i].unsqueeze(0)
          v = v + torch.nn.functional.normalize(x_i, dim=1) * self.fft_conv(h_i, v, self.B[i])  # skip connection

        v = v.transpose(1, 2)
        y = v + self.proj_output(v)  # skip connection

        return y

class Window(torch.nn.Module):
  def __init__(
      self,
      d_model: int,
      max_seq_len: int,
      fast_decay_pct: float = 0.3,
      slow_decay_pct: float = 1.5,
      target: float = 1e-2,
    ):
    super().__init__()
    self.b = torch.nn.Parameter(torch.zeros((1, d_model, 1)))
    min_decay = math.log(target) / slow_decay_pct
    max_decay = math.log(target) / fast_decay_pct
    self.alphas = torch.nn.Parameter(
      torch.linspace(
        start=min_decay,
        end=max_decay,
        steps=d_model
      )[None, :, None]
    )
    self.t = torch.nn.Parameter(
      torch.linspace(
        start=0,
        end=1,
        steps=max_seq_len
      )[None, None, :], requires_grad=False
    )

  def forward(self, x):
    L = x.shape[2]
    c = torch.exp(self.alphas * self.t)[:, :, :L]
    x = x * (c + self.b)
    return x

class HyenaFilter(torch.nn.Module):
  def __init__(
      self,
      d_model: int,
      d_mlp: int,
      d_embed: int,
      N: int,
      n_layers: int = 4,
      max_seq_len: int = 128,
      omega: int = 8,
    ):
    assert n_layers >= 2, "n_layers must be at least 2"
    super().__init__()

    self.N = N
    self.d_model = d_model

    # Making this a parameter, even though it is not trained, ensures
    # it will be moved to the gpu with the rest of the model
    self.h = torch.nn.Parameter(torch.randn((N, d_model, max_seq_len)))

    self.window = Window(d_model, max_seq_len)

  def forward(self, L: int) -> torch.Tensor:
    h = self.h[:, :, :L]
    h = self.window(h)

    h = h / torch.norm(h, dim=-2, p=1, keepdim=True)

    return h

class SinActivation(torch.nn.Module):
    def __init__(self, w=1.0):
        super().__init__()
        self.w = w

    def forward(self, x):
        return torch.sin(self.w * x)

class ImplicitHyenaFilter(torch.nn.Module):
    def __init__(
        self,
        d_model: int,
        d_mlp: int,      # largura da mlp
        N: int,
        max_seq_len: int
    ):
        super().__init__()
        self.d_model = d_model
        self.N = N
        self.emb_dim = 3 # tempo, seno, cosseno

        self.mlp = torch.nn.Sequential(
            torch.nn.Linear(self.emb_dim, d_mlp),
            SinActivation(),
            torch.nn.Linear(d_mlp, d_mlp),
            SinActivation(),
            torch.nn.Linear(d_mlp, N * d_model, bias=False) # saida de pesos do tamanho que precisamos
        )

        self.window = Window(d_model, max_seq_len)

    def forward(self, L: int) -> torch.Tensor:

        device = self.mlp[0].weight.device
        t = torch.linspace(0, 1, L, device=device).view(1, L, 1)

        z = torch.cat([t, torch.sin(2 * math.pi * t), torch.cos(2 * math.pi * t)], dim=-1) # formato: (1, L, 3)

        h = self.mlp(z) # formato: (1, L, N * d_model)

        # FFTConv espera: (N, d_model, L)
        h = h.squeeze(0).transpose(0, 1)      # fica (N * d_model, L)
        h = h.view(self.N, self.d_model, L)   # fica (N, d_model, L)

        h = self.window(h)

        h = h / (torch.norm(h, dim=-2, p=1, keepdim=True) + 1e-8)
        return h

class FraudModel(torch.nn.Module):
    def __init__(self, num_features: int, config: HyenaConfig, num_blocks = 2):
        super().__init__()

        self.entrada = torch.nn.Linear(num_features, config.d_model)


        self.blocos_Hyena = torch.nn.ModuleList([
            HyenaBlock(config, use_mlp_filter=True) for _ in range(num_blocks)
        ])

        self.saida = torch.nn.Linear(config.d_model, 1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        v = self.entrada(x)


        for bloco in self.blocos_Hyena:
            v = bloco(v)


        v_ultima_transacao = v[:, -1, :]
        logits = self.saida(v_ultima_transacao)
        return logits

class DatasetFraudeSequencial(torch.utils.data.Dataset):
  def __init__(self, caminho_csv: str, tamanho_sequencia: int=128):
    df = pd.read_csv(caminho_csv)
    df = df.sort_values('Time')
    self.tamanho_sequencia = tamanho_sequencia
    # 'Class' (0 = Normal, 1 = Fraude)
    y_raw = df['Class'].values
    X_raw = df.drop(columns=['Class']).values
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_raw)
    self.X = torch.tensor(X_scaled, dtype=torch.float32)
    self.y = torch.tensor(y_raw, dtype=torch.float32) # float32 para a BCEWithLogitsLoss depois

    print(f"Dataset pronto! Total de transações: {len(self.X)}. Features: {self.X.shape[1]}")
  def __len__(self):
    return len(self.X) - self.tamanho_sequencia + 1

  def __getitem__(self, idx):

    sequencia_X = self.X[idx : idx + self.tamanho_sequencia]

    label_y = self.y[idx + self.tamanho_sequencia - 1].unsqueeze(0)

    return sequencia_X, label_y

TAMANHO_CONTEXTO = 128 # Vai olhar 128 transacoes no tempo
TAMANHO_LOTE = 64      # Vai mandar 64 clientes  por vez para a GPU


dataset_fraude = DatasetFraudeSequencial(
    caminho_csv='./dataset/creditcard.csv',
    tamanho_sequencia=TAMANHO_CONTEXTO
)

dataloader_treino = torch.utils.data.DataLoader(
    dataset_fraude,
    batch_size=TAMANHO_LOTE,
    shuffle=True,
    num_workers=2,
    drop_last=True
)


print("\nVerificando o formato do primeiro Lote (Batch)...")
for lote_X, lote_y in dataloader_treino:
    print(f"Formato do X (Entrada do Hyena): {lote_X.shape}")
    print(f"Formato do y (Resposta esperada): {lote_y.shape}")
    break

config_model = HyenaConfig(
    d_model=128,
    n_layers=2,
    d_embed=33,
    d_filter_mlp=64,
    n_filter_layers=4,
    context_length=128,     #(TAMANHO_CONTEXTO)
    short_conv_size=3,
    order=2,
    pdrop_hyena=0.1,        # 10% de dropout para evitar overfitting
    pdrop_embed=0.2,
    omega=12,
    epochs=10,
    learning_rate=1e-4,
    betas=(0.9, 0.98),
    weight_decay=0.01,
    device_type="cuda" if torch.cuda.is_available() else "cpu",
    precision="bf16",
    batch_size=256,
    num_workers=4,
)
device = torch.device(config_model.device_type)
print(f"Iniciando treinamento na unidade: {device.type.upper()}")

model = FraudModel(num_features=30, config=config_model).to(device)


# conta do peso: (Total Negativos / Total Positivos) = 284315 / 492 = 577
# falso negativo doi bem mais que falso positivo
peso_fraude = torch.tensor([577.0]).to(device)
criterion = torch.nn.BCEWithLogitsLoss(pos_weight=peso_fraude)

optimizer = torch.optim.Adam(model.parameters(), lr=config_model.learning_rate)

for epoch in range(config_model.epochs):
    model.train()
    loss_acumulada = 0.0

    for batch_X, batch_y in dataloader_treino:


        batch_X = batch_X.to(device)
        batch_y = batch_y.to(device)

        optimizer.zero_grad()


        logits = model(batch_X)


        loss = criterion(logits, batch_y)


        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()


        loss_acumulada += loss.item()

    loss_media = loss_acumulada / len(dataloader_treino)
    print(f"Época {epoch+1:02d}/{config_model.epochs} | Loss Média: {loss_media:.4f}")

print("Concluido o treinamento.\n")

print("Testando modelo\n")


model.eval()

todas_previsoes = []
todos_reais = []


with torch.no_grad():
    for batch_X, batch_y in dataloader_treino:
        batch_X = batch_X.to(device)


        logits = model(batch_X)

        probabilidades = torch.sigmoid(logits)
        # >0.5 fraude
        previsoes_binarias = (probabilidades > 0.5).float()

        todas_previsoes.extend(previsoes_binarias.cpu().numpy())
        todos_reais.extend(batch_y.cpu().numpy())

print("="*40)
print("MATRIZ DE CONFUSÃO")
print("="*40)
# A matriz mostra: [Verdadeiros Negativos, Falsos Positivos]
#                  [Falsos Negativos, Verdadeiros Positivos]
print(confusion_matrix(todos_reais, todas_previsoes))

print("\n" + "="*40)
print("RELATÓRIO DE CLASSIFICAÇÃO")
print("="*40)
print(classification_report(todos_reais, todas_previsoes, target_names=['Normal', 'Fraude']))
caminho_arquivo = 'pesos_hyena_fraude.pth'

# Salvando apenas o dicionário de pesos (a forma mais leve e recomendada)
torch.save(model.state_dict(), caminho_arquivo)
